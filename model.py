# -*- coding: utf-8 -*-
"""Flight Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l61GzzwQBqKsaIz9xPldWt2Cm1ZkKZ4b

# **Flight Price Prediction**

# Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

"""# Reading the Data"""

df = pd.read_excel("/content/Data_Train.xlsx")
df

"""# Understanding the Data"""

df.dtypes

df.shape

df.size

df.columns

df.max()

df.min()

df.info()

df.describe()

df.corr()

df.nunique()

df.isnull().sum()

df = df.dropna()
df

df.isnull().sum()

"""# Exploratory Data Analysis"""

import missingno as no
no.bar(df, color='lightgreen')

sns.heatmap(df.isnull(), yticklabels='False', cmap='Oranges')

plt.figure(figsize=(14,8))
df.plot()
plt.show()

plt.figure(figsize=(14,8))
plt.style.use('seaborn-darkgrid')
sns.countplot(df.Source, palette='magma')
plt.show()

plt.figure(figsize=(25,8))
sns.boxplot(y='Price',x='Airline',data=df.sort_values('Price',ascending=False))

plt.figure(figsize=(15,5))
sns.violinplot(y='Price',x='Total_Stops',data=df.sort_values('Price',ascending=False))

sns.distplot(df['Price'], color='red')

"""# Data Preprocessing"""

df['Journey_day'] = pd.to_datetime(df.Date_of_Journey, format='%d/%m/%Y').dt.day

df['Journey_month'] = pd.to_datetime(df.Date_of_Journey, format='%d/%m/%Y').dt.month

df["Dep_hour"] = pd.to_datetime(df["Dep_Time"]).dt.hour

df["Dep_min"] = pd.to_datetime(df["Dep_Time"]).dt.minute

df["Arrival_hour"] = pd.to_datetime(df.Arrival_Time).dt.hour

df["Arrival_min"] = pd.to_datetime(df.Arrival_Time).dt.minute

df.drop(["Date_of_Journey", "Dep_Time", "Arrival_Time"], axis = 1, inplace = True)
df

duration = list(df["Duration"])
for i in range(len(duration)):
  if len(duration[i].split()) != 2:
    if "h" in duration[i]:
      duration[i] = duration[i].strip() + " 0m"
    else:
      duration[i] = "0h " + duration[i]

duration_hours = []
duration_minutes = []
for i in range(len(duration)):
  duration_hours.append(int(duration[i].split(sep='h')[0]))
  duration_minutes.append(int(duration[i].split(sep='m')[0].split()[-1]))

df['Duration_hours'] = duration_hours
df['Duration_minutes'] = duration_minutes

df.drop(["Duration"], axis = 1, inplace = True)

df

"""# Handling Categorical Data"""

Airline = df[['Airline']]
Airline = pd.get_dummies(Airline, drop_first=True)
Airline.head()

Source = df[['Source']]
Source = pd.get_dummies(Source, drop_first=True)
Source.head()

Destination = df[['Destination']]
Destination = pd.get_dummies(Destination, drop_first=True)
Destination.head()

df.replace({"non-stop": 0, "1 stop": 1, "2 stops": 2, 
            "3 stops": 3, "4 stops": 4}, inplace = True)
df.head()

df = pd.concat([df, Airline, Source, Destination], axis = 1)
df.drop(["Airline", "Source", "Destination", "Route", "Additional_Info"], axis = 1, inplace = True)
df.head()

df.shape

df.columns

"""# Splitting the Data into Dependent and Independent Variables"""

x = df.drop(['Price'], axis=1)
y = df['Price']

"""# Feature Importance"""

# from sklearn.ensemble import ExtraTreesClassifier
# model = ExtraTreesClassifier()
# model.fit(x,y)
# print(model.feature_importances_)

# feat_imp = pd.Series(model.feature_importances_, index=x.columns)
# feat_imp.nlargest(5).plot(kind='barh')

from sklearn.feature_selection import mutual_info_classif
mutual_info_classif(x,y)

plt.figure(figsize = (12,8))
imp = pd.Series(mutual_info_classif(x,y), index=x.columns)
imp.nlargest(7).plot(kind='barh')
plt.show()

"""# Training and Testing the Data"""

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=7)

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestRegressor

"""# Linear Regression"""

lr = LinearRegression()
lr.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = lr.predict(xtrain)
ypred_test = lr.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac1 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac1)

"""## Error"""

print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ypred_test))
print('Mean Squared Error:', metrics.mean_squared_error(ytest, ypred_test))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, ypred_test)))

"""# Decission Tree Regressor"""

dt = DecisionTreeRegressor(max_depth=10)
dt.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = dt.predict(xtrain)
ypred_test = dt.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac2 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac2)

"""## Error"""

print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ypred_test))
print('Mean Squared Error:', metrics.mean_squared_error(ytest, ypred_test))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, ypred_test)))

"""# K-Nearest Neighbors Regressor"""

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = knn.predict(xtrain)
ypred_test = knn.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac3 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac3)

"""## Error"""

print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ypred_test))
print('Mean Squared Error:', metrics.mean_squared_error(ytest, ypred_test))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, ypred_test)))

"""# Gaussian Naive Bayes"""

gnb = GaussianNB()
gnb.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = gnb.predict(xtrain)
ypred_test = gnb.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac4 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac4)

"""## Error"""

print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ypred_test))
print('Mean Squared Error:', metrics.mean_squared_error(ytest, ypred_test))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, ypred_test)))

"""# Random Forest Regressor"""

rf = RandomForestRegressor(max_depth=10, random_state=30)
rf.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = rf.predict(xtrain)
ypred_test = rf.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac5 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac5)

"""## Error"""

print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, ypred_test))
print('Mean Squared Error:', metrics.mean_squared_error(ytest, ypred_test))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, ypred_test)))

"""# Comparing Accuracies:"""

accuracy =  {ac1: 'Linear Regression', ac2:'Decission Tree Regressor', ac3:'KNN Regressor', ac4: 'Gaussian Naive Bayes', ac5: 'Random Forest Regressor'}

plt.figure(figsize=(14, 10))
model_accuracies = list(accuracy.values())
model_names = list(accuracy.keys())
sns.barplot(x=model_accuracies, y=model_names, palette='gist_rainbow');

"""As accuracy of Random Forest Regressor algorithm is more ie. 84.14% ~ 85%

Hence we will save the model.

# âœ” Saving the Model
"""

import pickle
pickle.dump(rf, open('model.pkl', 'wb'))